{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336f7093-e664-4c45-906a-4740fa5d204d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350db4e1-9af4-4580-a63a-831ba9430334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libs\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "# third-party libs\n",
    "import requests\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "AV_KEY = os.environ[\"AV_KEY\"]\n",
    "BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "TICKERS = {\n",
    "    \"TSLA\": \"Tesla\",\n",
    "    \"F\": \"Ford\",\n",
    "    \"GM\": \"GM\",\n",
    "    \"RIVN\": \"Rivian\",\n",
    "    \"LCID\": \"Lucid\",\n",
    "    \"TM\": \"Toyota\",\n",
    "    \"HMC\": \"Honda\",\n",
    "    \"NIO\": \"NIO\",\n",
    "    \"XPEV\": \"XPeng\",\n",
    "    \"STLA\": \"Stellantis\",\n",
    "    \"PSNY\": \"Polestar\",\n",
    "    \"LI\": \"Li Auto\",\n",
    "    \"RACE\": \"Ferrari\",\n",
    "    \"LCII\": \"LCI Industries\",\n",
    "    \"ALV\": \"Autoliv\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b15a93-d489-4a2c-98a9-1150afd13a03",
   "metadata": {},
   "source": [
    "## Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efa05d8-bdf1-43c4-a390-8c2fcab4dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"agent3_jsons\"  # keeps JSONs out of the root\n",
    "os.makedirs(OUT_DIR, exist_ok=True)  # creating once\n",
    "\n",
    "\n",
    "def fetch_news_sentiment(symbol: str,\n",
    "                         company: str,\n",
    "                         api_key: str,\n",
    "                         top_n: int = 10) -> list[dict]:\n",
    "    params = {\n",
    "        \"function\": \"NEWS_SENTIMENT\",\n",
    "        \"tickers\": symbol,\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "    resp = requests.get(BASE_URL, params=params, timeout=30)\n",
    "\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"Alpha Vantage error {resp.status_code}: {resp.text}\")\n",
    "\n",
    "\n",
    "    articles = resp.json().get(\"feed\", [])[:top_n]\n",
    "\n",
    "\n",
    "    cleaned = [\n",
    "        {\n",
    "            \"company\": company,\n",
    "            \"text\": art[\"title\"],\n",
    "            \"timestamp\": art[\"time_published\"]\n",
    "        }\n",
    "        for art in articles\n",
    "        if len(art[\"title\"]) > 30  # filter ultra-short headlines\n",
    "    ]\n",
    "\n",
    "\n",
    "    fname = f\"{company.lower().replace(' ', '_')}_agent3_news.json\"\n",
    "    out_file = os.path.join(OUT_DIR, fname)  # new path\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cleaned, f, indent=2)\n",
    "\n",
    "\n",
    "    print(f\"Saved {len(cleaned)} items → {out_file}\")\n",
    "    return cleaned\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7bbba-8797-49a0-b487-6b8a9c58fb36",
   "metadata": {},
   "source": [
    "## Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1251978-6f62-49e8-9d82-51c078bf9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt_sentiment(\n",
    "        text: str,\n",
    "        company_name: str,\n",
    "        model: str = \"gpt-4o-mini\",\n",
    "        temperature: float = 0.3,\n",
    "        max_retries: int = 3\n",
    "    ) -> tuple[float | None, str | None]:\n",
    "    \"\"\"\n",
    "    Query OpenAI to obtain a sentiment score in the range [-1, 1]\n",
    "    and a one-word rationale for `text` regarding `company_name`.\n",
    "    Returns (score, reason).  None is returned on failure.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an investor sentiment analyst.\n",
    "\n",
    "Company: {company_name}\n",
    "Text: \"{text}\"\n",
    "\n",
    "Task: On a scale of -1 (very negative) to +1 (very positive), rate the sentiment toward this company.\n",
    "Also return a one-word reason.\n",
    "\n",
    "Respond in this exact JSON format:\n",
    "{{\"score\": <number>, \"reason\": \"<word>\"}}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=temperature\n",
    "            )\n",
    "            reply = response.choices[0].message.content.strip()\n",
    "            parsed = json.loads(reply)\n",
    "\n",
    "\n",
    "            score = float(parsed.get(\"score\"))\n",
    "            reason = str(parsed.get(\"reason\"))\n",
    "            return score, reason\n",
    "\n",
    "\n",
    "        except Exception as err:\n",
    "            print(f\"[attempt {attempt}/{max_retries}] Error: {err}\")\n",
    "            time.sleep(2 * attempt)  # simple back-off\n",
    "\n",
    "\n",
    "    # all retries exhausted\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f56006d-208d-4872-9999-b06dfc26c4f6",
   "metadata": {},
   "source": [
    "## Agent 3 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2900c70-7369-4b2a-8c52-8975e483f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent3(\n",
    "        symbol: str,\n",
    "        company: str,\n",
    "        api_key: str,\n",
    "        top_n: int = 10,\n",
    "        pause: float = 1.0\n",
    "    ) -> dict:\n",
    "    \"\"\"\n",
    "    End-to-end pipeline for a single company:\n",
    "    1. Download recent headlines.\n",
    "    2. Score each headline with GPT.\n",
    "    3. Aggregate into a dashboard-style dictionary.\n",
    "    \"\"\"\n",
    "    # 1 ▸ data collection\n",
    "    data = fetch_news_sentiment(symbol, company, api_key, top_n=top_n)\n",
    "\n",
    "\n",
    "    # 2 ▸ sentiment scoring\n",
    "    for item in data:\n",
    "        score, reason = call_gpt_sentiment(item[\"text\"], company)\n",
    "        item[\"score\"] = score\n",
    "        item[\"reason\"] = reason\n",
    "        time.sleep(pause)  # light throttle\n",
    "\n",
    "\n",
    "    # 3 ▸ tidy DataFrame\n",
    "    df = pd.DataFrame([d for d in data if d[\"score\"] is not None])\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y%m%dT%H%M%S\")\n",
    "    df[\"date\"] = df[\"timestamp\"].dt.date\n",
    "    df[\"score\"] = df[\"score\"].astype(float)\n",
    "\n",
    "\n",
    "    if df.empty:  # fallback in rare no-data case\n",
    "        return {\"ticker\": symbol, \"error\": \"no valid scores\"}\n",
    "\n",
    "\n",
    "    # 4 ▸ summary statistics\n",
    "    avg = df[\"score\"].mean()\n",
    "    stdev = df[\"score\"].std()\n",
    "    conf = max(0.0, 1.0 - stdev)\n",
    "\n",
    "\n",
    "    top_pos = df.loc[df[\"score\"].idxmax()]\n",
    "    top_neg = df.loc[df[\"score\"].idxmin()]\n",
    "\n",
    "\n",
    "    implication = (\n",
    "        \"Strong upside potential\"  if avg > 0.6 else\n",
    "        \"Moderate upside potential\" if avg > 0.3 else\n",
    "        \"Neutral to mild optimism\"  if avg > 0.1 else\n",
    "        \"Neutral\"  if -0.1 <= avg <= 0.1 else\n",
    "        \"Mild downside pressure\"  if avg > -0.3 else\n",
    "        \"Moderate downside pressure\"if avg > -0.6 else\n",
    "        \"Strong downside pressure\"\n",
    "    )\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"ticker\": symbol,\n",
    "        \"sentiment_score\": round(avg, 3),\n",
    "        \"sentiment_label\": (\n",
    "            \"Bullish\" if avg > 0.25 else\n",
    "            \"Neutral\" if -0.25 <= avg <= 0.25 else\n",
    "            \"Bearish\"\n",
    "        ),\n",
    "        \"confidence\": round(conf, 3),\n",
    "        \"n_docs\": int(df.shape[0]),\n",
    "        \"weighted_stdev\": round(stdev, 3),\n",
    "        \"value_implication\": implication,\n",
    "        \"top_positive\": {\n",
    "            \"score\": round(top_pos[\"score\"], 3),\n",
    "            \"snippet\": top_pos[\"text\"]\n",
    "        },\n",
    "        \"top_negative\": {\n",
    "            \"score\": round(top_neg[\"score\"], 3),\n",
    "            \"snippet\": top_neg[\"text\"]\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671afad7-d213-49a3-9f4a-2e21eb94f2b0",
   "metadata": {},
   "source": [
    "## Single company test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ecf1c78-c992-4753-808d-13831d581e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5 items → tesla_agent3_news.json\n",
      "{\n",
      "  \"ticker\": \"TSLA\",\n",
      "  \"sentiment_score\": 0.2,\n",
      "  \"sentiment_label\": \"Neutral\",\n",
      "  \"confidence\": 0.654,\n",
      "  \"n_docs\": 5,\n",
      "  \"weighted_stdev\": 0.346,\n",
      "  \"value_implication\": \"Neutral to mild optimism\",\n",
      "  \"top_positive\": {\n",
      "    \"score\": 0.8,\n",
      "    \"snippet\": \"Tesla Valuation 'Could Far Exceed Current Levels': Analyst Sees 2 Segments Driving Most Upside  ( And It's Not Cars )  - Tesla  ( NASDAQ:TSLA ) \"\n",
      "  },\n",
      "  \"top_negative\": {\n",
      "    \"score\": 0.0,\n",
      "    \"snippet\": \"What's Going On With Li Auto Stock Tuesday? - Li Auto  ( NASDAQ:LI ) \"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = run_agent3(\"TSLA\", \"Tesla\", AV_KEY, top_n=5)\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e13b01c-063a-4b2c-b7b6-2e64e22b2004",
   "metadata": {},
   "source": [
    "## All companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fca76a7-c6da-42db-b40e-10f32881c9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Processing Tesla (TSLA)\n",
      "Saved 5 items → tesla_agent3_news.json\n",
      "\n",
      "▶ Processing Ford (F)\n",
      "Saved 4 items → ford_agent3_news.json\n",
      "\n",
      "▶ Processing GM (GM)\n",
      "Saved 5 items → gm_agent3_news.json\n",
      "\n",
      "▶ Processing Rivian (RIVN)\n",
      "Saved 4 items → rivian_agent3_news.json\n",
      "\n",
      "▶ Processing Lucid (LCID)\n",
      "Saved 5 items → lucid_agent3_news.json\n",
      "\n",
      "▶ Processing Toyota (TM)\n",
      "Saved 4 items → toyota_agent3_news.json\n",
      "\n",
      "▶ Processing Honda (HMC)\n",
      "Saved 5 items → honda_agent3_news.json\n",
      "\n",
      "▶ Processing NIO (NIO)\n",
      "Saved 5 items → nio_agent3_news.json\n",
      "\n",
      "▶ Processing XPeng (XPEV)\n",
      "Saved 5 items → xpeng_agent3_news.json\n",
      "\n",
      "▶ Processing Stellantis (STLA)\n",
      "Saved 5 items → stellantis_agent3_news.json\n",
      "\n",
      "▶ Processing Polestar (PSNY)\n",
      "Saved 5 items → polestar_agent3_news.json\n",
      "\n",
      "▶ Processing Li Auto (LI)\n",
      "Saved 5 items → li auto_agent3_news.json\n",
      "\n",
      "▶ Processing Ferrari (RACE)\n",
      "Saved 5 items → ferrari_agent3_news.json\n",
      "\n",
      "▶ Processing LCI Industries (LCII)\n",
      "Saved 5 items → lci industries_agent3_news.json\n",
      "\n",
      "▶ Processing Autoliv (ALV)\n",
      "Saved 5 items → autoliv_agent3_news.json\n",
      "\n",
      "✅ Saved universe summary → agent3_universe_2025-07-29.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>n_docs</th>\n",
       "      <th>weighted_stdev</th>\n",
       "      <th>value_implication</th>\n",
       "      <th>top_positive</th>\n",
       "      <th>top_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.160</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.642</td>\n",
       "      <td>5</td>\n",
       "      <td>0.358</td>\n",
       "      <td>Neutral to mild optimism</td>\n",
       "      <td>{'score': 0.8, 'snippet': 'Tesla Valuation 'Co...</td>\n",
       "      <td>{'score': 0.0, 'snippet': 'What's Going On Wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.350</td>\n",
       "      <td>4</td>\n",
       "      <td>0.650</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>{'score': 0.5, 'snippet': 'Insights Into Ford ...</td>\n",
       "      <td>{'score': -1.0, 'snippet': 'DTE Energy Misses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GM</td>\n",
       "      <td>0.240</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.512</td>\n",
       "      <td>5</td>\n",
       "      <td>0.488</td>\n",
       "      <td>Neutral to mild optimism</td>\n",
       "      <td>{'score': 0.7, 'snippet': 'Mary Kay Has GM Thi...</td>\n",
       "      <td>{'score': -0.5, 'snippet': 'Ford Q2 Earnings C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RIVN</td>\n",
       "      <td>0.075</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.432</td>\n",
       "      <td>4</td>\n",
       "      <td>0.568</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>{'score': 0.5, 'snippet': 'Rivian Automotive  ...</td>\n",
       "      <td>{'score': -0.7, 'snippet': 'Why Is Wall Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LCID</td>\n",
       "      <td>0.180</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.483</td>\n",
       "      <td>5</td>\n",
       "      <td>0.517</td>\n",
       "      <td>Neutral to mild optimism</td>\n",
       "      <td>{'score': 0.7, 'snippet': 'Lucid and Timothée ...</td>\n",
       "      <td>{'score': -0.5, 'snippet': 'Lucid Is Sinking T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  sentiment_score sentiment_label  confidence  n_docs  weighted_stdev  \\\n",
       "0   TSLA            0.160         Neutral       0.642       5           0.358   \n",
       "1      F           -0.075         Neutral       0.350       4           0.650   \n",
       "2     GM            0.240         Neutral       0.512       5           0.488   \n",
       "3   RIVN            0.075         Neutral       0.432       4           0.568   \n",
       "4   LCID            0.180         Neutral       0.483       5           0.517   \n",
       "\n",
       "          value_implication  \\\n",
       "0  Neutral to mild optimism   \n",
       "1                   Neutral   \n",
       "2  Neutral to mild optimism   \n",
       "3                   Neutral   \n",
       "4  Neutral to mild optimism   \n",
       "\n",
       "                                        top_positive  \\\n",
       "0  {'score': 0.8, 'snippet': 'Tesla Valuation 'Co...   \n",
       "1  {'score': 0.5, 'snippet': 'Insights Into Ford ...   \n",
       "2  {'score': 0.7, 'snippet': 'Mary Kay Has GM Thi...   \n",
       "3  {'score': 0.5, 'snippet': 'Rivian Automotive  ...   \n",
       "4  {'score': 0.7, 'snippet': 'Lucid and Timothée ...   \n",
       "\n",
       "                                        top_negative  \n",
       "0  {'score': 0.0, 'snippet': 'What's Going On Wit...  \n",
       "1  {'score': -1.0, 'snippet': 'DTE Energy Misses ...  \n",
       "2  {'score': -0.5, 'snippet': 'Ford Q2 Earnings C...  \n",
       "3  {'score': -0.7, 'snippet': 'Why Is Wall Street...  \n",
       "4  {'score': -0.5, 'snippet': 'Lucid Is Sinking T...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_full_universe(api_key: str = AV_KEY,\n",
    "                      top_n: int = 10,\n",
    "                      pause: float = 1.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Execute Agent 3 across the full 15-ticker universe.\n",
    "    Returns a DataFrame and writes a consolidated JSON output.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "\n",
    "    for symbol, company in TICKERS.items():\n",
    "        print(f\"\\n▶ Processing {company} ({symbol})\")\n",
    "        res = run_agent3(symbol, company, api_key, top_n=top_n, pause=pause)\n",
    "        results.append(res)\n",
    "\n",
    "\n",
    "    df_all = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "    # save to disk\n",
    "    out_file = f\"agent3_universe_{datetime.utcnow().date()}.json\"\n",
    "    df_all.to_json(out_file, orient=\"records\", indent=2)\n",
    "    print(f\"\\nSaved universe summary → {out_file}\")\n",
    "\n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "df_summary = run_full_universe(top_n=5)  # quick smoke test\n",
    "df_summary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4f2fe-5bad-483d-af8f-e04dc5da2850",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd630e66-bf90-49d7-b0cb-16f912b2678a",
   "metadata": {},
   "source": [
    "## Loading the headline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac956c97-c375-48a8-93e9-296dcba28e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 headlines loaded across 15 companies.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autoliv</td>\n",
       "      <td>GPC Tops Q2 Earnings Estimates, Slashes 2025 V...</td>\n",
       "      <td>20250722T141200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autoliv</td>\n",
       "      <td>Autoliv Hit Sales and Margin Records in Q2</td>\n",
       "      <td>20250718T234607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autoliv</td>\n",
       "      <td>Autoliv  ( ALV )  Q2 2025 Earnings Call Transc...</td>\n",
       "      <td>20250718T163906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autoliv</td>\n",
       "      <td>Are You a Momentum Investor? This 1 Stock Coul...</td>\n",
       "      <td>20250718T135001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autoliv</td>\n",
       "      <td>Autoliv Q2 Earnings - Autoliv  ( NYSE:ALV )</td>\n",
       "      <td>20250718T123702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company                                               text        timestamp\n",
       "0  Autoliv  GPC Tops Q2 Earnings Estimates, Slashes 2025 V...  20250722T141200\n",
       "1  Autoliv         Autoliv Hit Sales and Margin Records in Q2  20250718T234607\n",
       "2  Autoliv  Autoliv  ( ALV )  Q2 2025 Earnings Call Transc...  20250718T163906\n",
       "3  Autoliv  Are You a Momentum Investor? This 1 Stock Coul...  20250718T135001\n",
       "4  Autoliv       Autoliv Q2 Earnings - Autoliv  ( NYSE:ALV )   20250718T123702"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob, json, pandas as pd\n",
    "\n",
    "\n",
    "OUT_DIR = \"agent3_jsons\"\n",
    "\n",
    "\n",
    "def load_agent3_jsons(folder: str = OUT_DIR) -> pd.DataFrame:\n",
    "    \"\"\"Read every *_agent3_news.json file and return one DataFrame.\"\"\"\n",
    "    rows = []\n",
    "    for path in glob.glob(os.path.join(folder, \"*_agent3_news.json\")):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            rows.extend(json.load(f))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "df_all = load_agent3_jsons()\n",
    "print(f\"{df_all.shape[0]} headlines loaded across {df_all['company'].nunique()} companies.\")\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be9985-ca0a-4271-97dc-16d25d1c0255",
   "metadata": {},
   "source": [
    "## Adding model scores + internal consistency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14d5aaec-c353-4e71-ba26-f8f69371e96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa86c2cf1198430599268d909138e607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average intra-headline σ (k=3) = 0.036\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm  # progress bar\n",
    "\n",
    "def score_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply call_gpt_sentiment row-wise and append 'score' & 'reason'.\n",
    "    Existing scores are overwritten so you can re-run any time.\n",
    "    \"\"\"\n",
    "    scores, reasons = [], []\n",
    "    for txt, comp in tqdm(zip(df[\"text\"], df[\"company\"]), total=len(df)):\n",
    "        s, r = call_gpt_sentiment(txt, comp)\n",
    "        scores.append(s); reasons.append(r)\n",
    "    df = df.copy()\n",
    "    df[\"score\"] = scores\n",
    "    df[\"reason\"] = reasons\n",
    "    return df\n",
    "\n",
    "\n",
    "df_scored = score_dataframe(df_all)\n",
    "\n",
    "\n",
    "# reliability: variance when rescoring the SAME headline k times\n",
    "def calc_consistency(sample_df: pd.DataFrame, k: int = 3) -> float:\n",
    "    stdevs = []\n",
    "    for txt in sample_df[\"text\"]:\n",
    "        vals = [call_gpt_sentiment(txt, \"dummy\")[0] for _ in range(k)]\n",
    "        stdevs.append(pd.Series(vals).std())\n",
    "    return float(pd.Series(stdevs).mean())\n",
    "\n",
    "\n",
    "reliab = calc_consistency(df_scored.sample(50, random_state=1))\n",
    "print(f\"Average intra-headline σ (k=3) = {reliab:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc8600b4-4c77-4a76-bfc1-09a8d7503251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template saved → agent3_eval_template.csv  (72 rows)\n"
     ]
    }
   ],
   "source": [
    "# determine a feasible sample size\n",
    "sample_n = min(len(df_scored), 200)\n",
    "\n",
    "\n",
    "(df_scored[[\"company\", \"text\", \"score\"]]\n",
    " .sample(sample_n, random_state=0)\n",
    " .assign(expected_score=\"\")  # column for manual labels\n",
    " .to_csv(\"agent3_eval_template.csv\", index=False))\n",
    "\n",
    "\n",
    "print(f\"Template saved → agent3_eval_template.csv  ({sample_n} rows)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a366ea60-b768-4b1a-be63-fbc99689f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.175  |  R² = 0.382  |  ρ = 0.747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "df_lab = pd.read_csv(\"agent3_eval_template.csv\")\n",
    "df_lab = df_lab.dropna(subset=[\"expected_score\"]).astype({\"expected_score\": float})\n",
    "\n",
    "\n",
    "rmse = mean_squared_error(df_lab[\"expected_score\"], df_lab[\"score\"])\n",
    "r2 = r2_score(df_lab[\"expected_score\"], df_lab[\"score\"])\n",
    "rho = df_lab[[\"expected_score\", \"score\"]].corr().iloc[0, 1]\n",
    "\n",
    "\n",
    "print(f\"RMSE = {rmse:.3f}  |  R² = {r2:.3f}  |  ρ = {rho:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2c24e9-2dd7-42da-adab-683f6bec3796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4o vs FinBERT correlation ρ = -0.042\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "\n",
    "_tok = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "\n",
    "def finbert_score(txt: str) -> float:\n",
    "    inputs = _tok(txt, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        logits = _model(**inputs).logits.squeeze()\n",
    "    probs = torch.softmax(logits, dim=0).numpy()  # [neg, neu, pos]\n",
    "    return float(probs[2] - probs[0])\n",
    "\n",
    "\n",
    "df_scored[\"finbert\"] = df_scored[\"text\"].apply(finbert_score)\n",
    "corr = df_scored[[\"score\", \"finbert\"]].corr().iloc[0, 1]\n",
    "print(f\"GPT-4o vs FinBERT correlation ρ = {corr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c9354-89ca-4ffc-832b-cc398c62452f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch_env_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
